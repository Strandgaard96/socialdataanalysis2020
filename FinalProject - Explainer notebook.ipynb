{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and data loading for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook,curdoc, show\n",
    "from bokeh.models import ColumnDataSource, FactorRange,Grid, HBar, LinearAxis, Plot,LabelSet,Legend\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.transform import factor_cmap,dodge\n",
    "from bokeh.palettes import Spectral10\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.models import Select\n",
    "from bokeh.layouts import column,row\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# select a palette\n",
    "from bokeh.palettes import Spectral3\n",
    "from bokeh.palettes import Category20b_13 as palette\n",
    "from bokeh.palettes import Category20b_14 as palette2\n",
    "# itertools handles the cycling\n",
    "import itertools  \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import tree\n",
    "\n",
    "sns.set(style='darkgrid', palette='muted', color_codes=True)\n",
    "\n",
    "\n",
    "\n",
    "# Magic command useful for jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plot size. \n",
    "plt.rcParams['figure.figsize'] = [13, 6]\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crash = pd.read_csv('data/Motor_Vehicle_Collisions_-_Crashes.csv')\n",
    "df_vehicle = pd.read_csv('data/Motor_Vehicle_Collisions_-_Vehicles.csv')\n",
    "df_people = pd.read_csv('data/Motor_Vehicle_Collisions_-_Person.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project three datasets were used. The main dataset was a detailed table of vehicle crash incidends in New York from 2012 to 2019. For each incident there was a unique collision ID which the two other datasets were based upon. These datasets were records of the people and vehicles involved in the crashes of the first dataset. \n",
    "\n",
    "These datasets where chosen because of the large amount of variables. They had the core variables that are essential to this sort of analysis like; time of crash, date of crash and location of crash (GPS coordinates and Borough). In addition there were several interesting variables like street name of crash, number of persons killed/injured and contributing factor of the crash. \n",
    "The problem with such a dataset would not be to search heavily for parameters to analyse, but rather carefully select a few of the vast possibilities in the dataset. \n",
    "\n",
    "The main goal was to be able to provide the user with easy to understand vizualizations. And in some cases provide tools for the user to interactively select what data they would like to see to encourage user engagement. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Basic stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw dataset stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To best explain how the preprocessing and cleaning was done, an overview of the initial raw dataset is given in this section. \n",
    "\n",
    "**Crashes:** \n",
    "- 1.67 M rows\n",
    "- 29 columns\n",
    "- 362 mb\n",
    "\n",
    "**Vehicles:** \n",
    "- 3.35 M rows\n",
    "- 25 columns\n",
    "- 551 MB\n",
    "\n",
    "**People:** \n",
    "- 3.91 M rows\n",
    "- 21 columns\n",
    "- 624 MB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and preprocessing\n",
    "\n",
    "Initially there were a lot of NaN values in the datasets as seen below. Therefore a lot of values had to be removed. To avoid losing lots of data from dropping NaNs, the appropriate columns from the three datasets were extracted. Many colums had over a million NaN values and would thus not be appropriate for analysis. Important parameters such as crash time, crash date and location (latitude/longitude/borough) had most of their values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRASH DATE                             0\n",
       "CRASH TIME                             0\n",
       "BOROUGH                           509839\n",
       "ZIP CODE                          510046\n",
       "LATITUDE                          201721\n",
       "LONGITUDE                         201721\n",
       "LOCATION                          201721\n",
       "ON STREET NAME                    330899\n",
       "CROSS STREET NAME                 570911\n",
       "OFF STREET NAME                  1433844\n",
       "NUMBER OF PERSONS INJURED             17\n",
       "NUMBER OF PERSONS KILLED              31\n",
       "NUMBER OF PEDESTRIANS INJURED          0\n",
       "NUMBER OF PEDESTRIANS KILLED           0\n",
       "NUMBER OF CYCLIST INJURED              0\n",
       "NUMBER OF CYCLIST KILLED               0\n",
       "NUMBER OF MOTORIST INJURED             0\n",
       "NUMBER OF MOTORIST KILLED              0\n",
       "CONTRIBUTING FACTOR VEHICLE 1       4518\n",
       "CONTRIBUTING FACTOR VEHICLE 2     227813\n",
       "CONTRIBUTING FACTOR VEHICLE 3    1563865\n",
       "CONTRIBUTING FACTOR VEHICLE 4    1649657\n",
       "CONTRIBUTING FACTOR VEHICLE 5    1666553\n",
       "COLLISION_ID                           0\n",
       "VEHICLE TYPE CODE 1                 5944\n",
       "VEHICLE TYPE CODE 2               280627\n",
       "VEHICLE TYPE CODE 3              1535028\n",
       "VEHICLE TYPE CODE 4              1621922\n",
       "VEHICLE TYPE CODE 5              1661476\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crash.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_ID                            0\n",
       "COLLISION_ID                         0\n",
       "CRASH_DATE                           0\n",
       "CRASH_TIME                           0\n",
       "VEHICLE_ID                           0\n",
       "STATE_REGISTRATION              152152\n",
       "VEHICLE_TYPE                    132033\n",
       "VEHICLE_MAKE                   1713629\n",
       "VEHICLE_MODEL                  3294186\n",
       "VEHICLE_YEAR                   1720659\n",
       "TRAVEL_DIRECTION               1607383\n",
       "VEHICLE_OCCUPANTS              1668167\n",
       "DRIVER_SEX                     1917770\n",
       "DRIVER_LICENSE_STATUS          1971646\n",
       "DRIVER_LICENSE_JURISDICTION    1961964\n",
       "PRE_CRASH                       850587\n",
       "POINT_OF_IMPACT                1628802\n",
       "VEHICLE_DAMAGE                 1640673\n",
       "VEHICLE_DAMAGE_1               2277825\n",
       "VEHICLE_DAMAGE_2               2557501\n",
       "VEHICLE_DAMAGE_3               2745625\n",
       "PUBLIC_PROPERTY_DAMAGE         1528863\n",
       "PUBLIC_PROPERTY_DAMAGE_TYPE    3331696\n",
       "CONTRIBUTING_FACTOR_1            92818\n",
       "CONTRIBUTING_FACTOR_2          1620959\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vehicle.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_ID                      0\n",
       "COLLISION_ID                   0\n",
       "CRASH_DATE                     0\n",
       "CRASH_TIME                     0\n",
       "PERSON_ID                     19\n",
       "PERSON_TYPE                    0\n",
       "PERSON_INJURY                  0\n",
       "VEHICLE_ID                151782\n",
       "PERSON_AGE                294988\n",
       "EJECTION                 1911145\n",
       "EMOTIONAL_STATUS         1864739\n",
       "BODILY_INJURY            1864696\n",
       "POSITION_IN_VEHICLE      1910875\n",
       "SAFETY_EQUIPMENT         1910925\n",
       "PED_LOCATION             3858762\n",
       "PED_ACTION               3858863\n",
       "COMPLAINT                1864689\n",
       "PED_ROLE                  194895\n",
       "CONTRIBUTING_FACTOR_1    3859973\n",
       "CONTRIBUTING_FACTOR_2    3860035\n",
       "PERSON_SEX                468460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selection of columns used for analysis the datasets had the following columns and nan values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crash = df_crash[['CRASH DATE','CRASH TIME','BOROUGH', 'LATITUDE', 'LONGITUDE',\\\n",
    "         'ON STREET NAME', 'CROSS STREET NAME', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\\\n",
    "          'NUMBER OF PEDESTRIANS INJURED','NUMBER OF PEDESTRIANS KILLED','NUMBER OF CYCLIST INJURED','NUMBER OF CYCLIST KILLED',\\\n",
    "          'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED','CONTRIBUTING FACTOR VEHICLE 1',\\\n",
    "         'CONTRIBUTING FACTOR VEHICLE 2','COLLISION_ID','VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2']]\n",
    "df_vehicle = df_vehicle[['UNIQUE_ID','COLLISION_ID','CRASH_DATE','CRASH_TIME','VEHICLE_ID',\\\n",
    "                        'VEHICLE_TYPE','VEHICLE_YEAR','DRIVER_SEX','PRE_CRASH','POINT_OF_IMPACT','VEHICLE_DAMAGE']]\n",
    "df_people = df_people.drop(columns = ['PED_LOCATION','PED_ACTION','CONTRIBUTING_FACTOR_1','CONTRIBUTING_FACTOR_2',\\\n",
    "                                     'EJECTION','EMOTIONAL_STATUS','BODILY_INJURY','POSITION_IN_VEHICLE',\\\n",
    "                                     'SAFETY_EQUIPMENT','COMPLAINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRASH DATE                            0\n",
       "CRASH TIME                            0\n",
       "BOROUGH                          509839\n",
       "LATITUDE                         201721\n",
       "LONGITUDE                        201721\n",
       "ON STREET NAME                   330899\n",
       "CROSS STREET NAME                570911\n",
       "NUMBER OF PERSONS INJURED            17\n",
       "NUMBER OF PERSONS KILLED             31\n",
       "NUMBER OF PEDESTRIANS INJURED         0\n",
       "NUMBER OF PEDESTRIANS KILLED          0\n",
       "NUMBER OF CYCLIST INJURED             0\n",
       "NUMBER OF CYCLIST KILLED              0\n",
       "NUMBER OF MOTORIST INJURED            0\n",
       "NUMBER OF MOTORIST KILLED             0\n",
       "CONTRIBUTING FACTOR VEHICLE 1      4518\n",
       "CONTRIBUTING FACTOR VEHICLE 2    227813\n",
       "COLLISION_ID                          0\n",
       "VEHICLE TYPE CODE 1                5944\n",
       "VEHICLE TYPE CODE 2              280627\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crash.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_ID                0\n",
       "COLLISION_ID             0\n",
       "CRASH_DATE               0\n",
       "CRASH_TIME               0\n",
       "VEHICLE_ID               0\n",
       "VEHICLE_TYPE        132033\n",
       "VEHICLE_YEAR       1720659\n",
       "DRIVER_SEX         1917770\n",
       "PRE_CRASH           850587\n",
       "POINT_OF_IMPACT    1628802\n",
       "VEHICLE_DAMAGE     1640673\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vehicle.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_ID             0\n",
       "COLLISION_ID          0\n",
       "CRASH_DATE            0\n",
       "CRASH_TIME            0\n",
       "PERSON_ID            19\n",
       "PERSON_TYPE           0\n",
       "PERSON_INJURY         0\n",
       "VEHICLE_ID       151782\n",
       "PERSON_AGE       294988\n",
       "PED_ROLE         194895\n",
       "PERSON_SEX       468460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps was to decide on what to do with the rows containing NaN values. To avoid removing data as much as possible, it was decided to fille the missing values with 'Unspecified'. In this way the data would still count in analysis on rows without missing values. When the actual columns with NaN values were analyzed, 'Unspecified' could still be used to remove the rows at this point or simply include them in the analysis. Following this step all column had zero NaN values and could now be used for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other considerations**\n",
    "\n",
    "After the datasets had been cleaned of NaN values we had to consider all the 'bad' values in the dataset. This includes numbers that would be wrongfully entered when recorded or non-valid strings. An example was a Vehicle year recorded as 1100 which was deemed highly unlikely...\n",
    "\n",
    "The list of bad values included\n",
    "\n",
    "- Unlikely person ages. \n",
    "- Mispellings of vehicle type (Creating several groups of the same data in a groupby)\n",
    "- Unlikely Vehicle years\n",
    "- Incorrect latitude/longitudes. \n",
    "\n",
    "As the number of bad values was high for each column and in some cases dificult to identify it was deicded to handle them when appropriate as visualizations often revealed the bad values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataset stats\n",
    "\n",
    "After all the cleaning was done the final datasets had the following stats: \n",
    "\n",
    "**Crashes:** \n",
    "- 1.67 M rows\n",
    "- 20 columns\n",
    "\n",
    "**Vehicles:** \n",
    "- 3.35 M rows\n",
    "- 12 columns\n",
    "\n",
    "\n",
    "**People:** \n",
    "- 3.91 M rows\n",
    "- 11 columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Describe your data analysis and explain what you've learned about the dataset.\n",
    "\n",
    "- If relevant, talk about your machine-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
